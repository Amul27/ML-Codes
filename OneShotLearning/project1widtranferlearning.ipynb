{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese Network for One Shot Learning (Transfer Learning Applied)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Recap and introduction:\n",
    "So we saw that our siamese net did not perform quite well and we concluded that the possible reasons could be less data or poor architecture. The model we had was an overfit. We improve the model using transfer learning and we use the model weights of a standard VGG16 model (with weights corresponding to the imagenet dataset). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras import applications\n",
    "from keras import layers\n",
    "from keras import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load the VGG16 weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = applications.VGG16(weights = \"imagenet\", include_top=True, input_shape = (224,224,3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Preprocess the data for input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_path = '/home/amula/Desktop/TransLearnPC/NewTest/DataProcessed'\n",
    "imlist = sorted(os.listdir(imgs_path))\n",
    "imgs_list = []\n",
    "for im in imlist:\n",
    "    img = image.load_img('/home/amula/Desktop/TransLearnPC/NewTest/DataProcessed' + '/' + im, target_size=(224,224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x,axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    imgs_list.append(x)\n",
    "imgs_list = np.array(imgs_list)\n",
    "#print(imgs_list.shape)\n",
    "imgs_list = np.rollaxis(imgs_list,1,0) #this is the input format required for VGG\n",
    "imgs_list = imgs_list[0]\n",
    "#print(imgs_list.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Lets take the output from the 'fc1' layer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_layer_model = Model(inputs=model.input,outputs=model.get_layer(\"fc1\").output)\n",
    "#features = intermediate_layer_model.predict(imgs_list)\n",
    "#print(features.shape) #this would answer (600,4096)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Saving the features to be loaded later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name = \"pickpick.plk\"\n",
    "#fileObject = open(file_name,'ab')\n",
    "#pickle.dump(features,fileObject)\n",
    "#fileObject.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Loading the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 4096)\n",
      "(300, 4096)\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "file_name = \"/home/amula/Desktop/TransLearnPC/NewTest/pickpick.plk\"\n",
    "fileObject = open(file_name,'rb')\n",
    "features=pickle.load(fileObject)\n",
    "features1=pickle.load(fileObject)\n",
    "fileObject.close()\n",
    "print(features.shape)\n",
    "print(features1.shape)\n",
    "print(np.array_equal(features,features1)) #since the data was quite large we had to save it in two parts of 300 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine the features now\n",
    "featurescombined = np.zeros([600,4096])\n",
    "featurescombined[:300,:] = features[:,:]\n",
    "featurescombined[300:,:] = features1[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating Anchor Positive and Negative\n",
    "featuresAnc = np.zeros([200,4096])\n",
    "featuresPos = np.zeros([200,4096])\n",
    "featuresNeg = np.zeros([200,4096])\n",
    "\n",
    "for i in range(600):\n",
    "\tif (i+1)%3 == 1:\n",
    "\t\tfeaturesAnc[int(i/3),:] = featurescombined[i,:]\n",
    "\telif (i+1)%3 == 2:\n",
    "\t\tfeaturesPos[int(i/3),:] = featurescombined[i,:]\n",
    "\telif (i+1)%3 == 0:\n",
    "\t\tfeaturesNeg[int(i/3),:] = featurescombined[i,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arranging as Anc-Pos and Anc-Neg\n",
    "featuresAncPos = np.zeros([200,2*4096+1])\n",
    "featuresAncNeg = np.zeros([200,2*4096+1])\n",
    "\n",
    "for i in range(200):\n",
    "\tfeaturesAncPos[i,:4096] = (featuresAnc[i,:])\n",
    "\tfeaturesAncPos[i,4096:2*4096] = (featuresPos[i,:])\n",
    "\tfeaturesAncPos[i,2*4096] = 1\n",
    "\t\n",
    "\tfeaturesAncNeg[i,:4096] = (featuresAnc[i,:])\n",
    "\tfeaturesAncNeg[i,4096:2*4096] = (featuresNeg[i,:])\n",
    "\tfeaturesAncNeg[i,2*4096] = 0\n",
    "\t\n",
    "featuresMix = np.zeros([400,2*4096+1])\n",
    "for i in range(400):\n",
    "\tif i<200:\n",
    "\t\tfeaturesMix[i,:] = featuresAncPos[i,:]\n",
    "\telse:\n",
    "\t\tfeaturesMix[i,:] = featuresAncNeg[i-200,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Shuffle and split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 8193)\n",
      "(80, 8193)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "featuresShuffle = shuffle(featuresMix, random_state = 2)\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "Xytrain,Xytest = train_test_split(featuresShuffle, test_size = 0.2, random_state = 4)\n",
    "\n",
    "print(Xytrain.shape)\n",
    "print(Xytest.shape)\n",
    "\n",
    "X_train = Xytrain[:,:4096]-Xytrain[:,4096:2*4096]\n",
    "y_train = Xytrain[:,2*4096]\n",
    "\n",
    "X_test = Xytest[:,:4096]-Xytest[:,4096:2*4096]\n",
    "y_test = Xytest[:,2*4096]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Finally apply a classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  1.0\n",
      "Test Accuracy:  0.4625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf1 = SVC()\n",
    "clf1.fit(X_train, y_train)\n",
    "train_predict1 = clf1.predict(X_train)\n",
    "test_predict1 = clf1.predict(X_test)\n",
    "print(\"Train Accuracy: \", accuracy_score(train_predict1, y_train))\n",
    "print(\"Test Accuracy: \", accuracy_score(test_predict1, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Summary:\n",
    "still pretty lame accuracy, hence we conclude that the data should be more which is expected for a computer \n",
    "vision problem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
